%!TEX root = pset1.tex

\section{Ridge Regression}\label{sec:ridge_reg}
\subsection{Implementation}
Ridge regression is the particular case of regularized least squares with a quadratic regularizer term.  The error function that we aim to minimize over is given by:
\begin{equation} \label{eq:ridge_error_fn}
\frac{1}{2} \sum_{n=1}^{N} (t_n - \M{w}^T \phi (\M{x}_n) )^2 + \frac{\lambda}{2} \M{w}^T \M{w}
\end{equation}

The closed-form solution of this problem is well-known, and can be derived by setting the gradient of (\ref{eq:ridge_error_fn}) equal to zero.  The optimal solution for $\M{w}$ is provided by Bishop (2006), page 145:

\begin{equation} \label{eq:ridge_sol}
\M{w}_{ridge} = (\lambda \M{I} + \Phi^T \Phi)^{-1} \Phi^T \M{t}
\end{equation}

We coded this method in MATLAB and tested our program using data from Bishop Figure 1.4, varying the parameters of $\lambda$ and $M$.  For the extreme cases, we observed that if $\lambda \leq 0.0001$, then $\M{w}_{ridge} \approx \M{w}_{OLS}$, and if $\lambda \geq 100$, then $\M{w}_{ridge} \approx \M{0}$.

% Reference: Bishop (2006), pages 144-145

% TODO: add plots
% TODO: add description of results when M = 1, 3, 5

\subsection{Model Selection}
To optimize parameter values for $\lambda$ and $M$, we build our models using training data and then compare out-of-sample performance on validation data.  For this example, we performed a grid search over the ranges: $\log_{10}(\lambda) = \{-10,\ldots,10\}$, $M = \{0,\ldots, 9\}$.  We found that the model with $\lambda = 1$ and $M = 4$ yields the lowest MSE on validation data, so we select these to be the final parameter values.  This model leads to MSE = 0.1056 on the validation data and MSE = TODO on the test data.  

In general, we observe that models with relatively low MSE on the validation set tend to have relatively low MSE on the test set.  Heat maps of the MSE values for different parameter values are shown in Figure~\ref{fig:heat_map}.   As expected, test MSE is higher on average, and the plots are similar for most parameter values.  Discrepancies between the heat maps may be attributed to the prescence of an outlier in the training set.  In both heat maps, we see that the top left corner (high M, high $\lambda$), which corresponds to complex models with little regularization, lead to the worst performance on out-of-sample data.  

\begin{figure}[h!]
\centering
    \begin{subfigure}[b]{0.4\textwidth}
	\includegraphics[scale=0.55]{hw1_3_2.pdf}
	\caption{Validation MSE}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.4\textwidth}
	\includegraphics[scale=0.55]{hw1_3_2b.pdf}
	\caption{Test MSE}
    \end{subfigure}
\caption{Heat map of the MSE for ridge regression on the validation and test sets, varying the parameters $M$ and $\lambda$.  Color gradient from low MSE (navy blue) to high MSE (yellow).} \label{fig:heat_map}
\end{figure}